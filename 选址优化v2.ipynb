{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import transbigdata as tbd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "import transbigdata as tbd  # 假设tbd库有必要的GPS_to_grid和area_to_grid函数\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# 定义处理充电站数据的函数\n",
    "def process_charging_orders(station_info, step_length, params):\n",
    "    station_info_table = station_info[['station_id','lon','lat','max_capacity','charge_speed_station']].drop_duplicates().copy()\n",
    "    \n",
    "    station_info = station_info[station_info['num_current_car'] > 0]\n",
    "    station_info['time'] = pd.to_datetime(station_info['time'])\n",
    "    station_info['current_car'] = station_info['current_car'].apply(lambda a: ast.literal_eval(a))\n",
    "    station_info['waiting_car'] = station_info['waiting_car'].apply(lambda a: ast.literal_eval(a))\n",
    "    station_info.sort_values(by=['station_id', 'time'], inplace=True)\n",
    "\n",
    "    current_car_infos = station_info[['station_id', 'time', 'current_car']].explode('current_car')\n",
    "    current_car_infos = current_car_infos[~current_car_infos['current_car'].isnull()]\n",
    "    current_car_infos = current_car_infos.sort_values(by=['current_car', 'time'])[['current_car', 'time', 'station_id']]\n",
    "\n",
    "    waiting_car_infos = station_info[['station_id', 'time', 'waiting_car']].explode('waiting_car')\n",
    "    waiting_car_infos = waiting_car_infos[~waiting_car_infos['waiting_car'].isnull()]\n",
    "    waiting_car_infos = waiting_car_infos.sort_values(by=['waiting_car', 'time'])[['waiting_car', 'time', 'station_id']]\n",
    "\n",
    "    return  station_info_table , current_car_infos, waiting_car_infos\n",
    "\n",
    "\n",
    "# 计算充电订单\n",
    "def get_charging_order(station_info_table,current_car_infos, step_length):\n",
    "    current_car_infos['timegap'] = current_car_infos['time'].diff().dt.total_seconds().fillna(1000000).astype(int)\n",
    "    current_car_infos['order_id'] = (current_car_infos['timegap'] > step_length).cumsum()\n",
    "    charge_info_s = current_car_infos.groupby(['current_car', 'order_id']).first().reset_index()\n",
    "    charge_info_e = current_car_infos.groupby(['current_car', 'order_id']).last().reset_index()\n",
    "    charging_order = pd.merge(charge_info_s, charge_info_e, on=['current_car', 'order_id', 'station_id'])\n",
    "    charging_order = charging_order[['current_car', 'order_id', 'time_x', 'time_y', 'station_id']]\n",
    "    charging_order.columns = ['carid', 'order_id', 'stime', 'etime', 'station_id']\n",
    "    charging_order['duration'] = (charging_order['etime'] - charging_order['stime']).dt.total_seconds()\n",
    "    charging_order = charging_order[charging_order['duration'] > 0]\n",
    "    charging_orders = pd.merge(charging_order,station_info_table)\n",
    "    # 计算充电时长\n",
    "    charging_orders['duration'] = (charging_orders['etime']-charging_orders['stime']).dt.total_seconds()\n",
    "    return charging_orders\n",
    "\n",
    "def get_order(charging_orders,params,grid):\n",
    "    charging_order = charging_orders\n",
    "    charging_order['LONCOL'],charging_order['LATCOL'] = tbd.GPS_to_grid(charging_order['lon'],charging_order['lat'],params=params)\n",
    "    charging_order_agg = charging_order.groupby(['LONCOL','LATCOL'])['carid'].count().reset_index()\n",
    "    charging_order_agg = pd.merge(grid[['LONCOL','LATCOL']],charging_order_agg,on=['LONCOL','LATCOL'],how=\"left\")[['LONCOL','LATCOL','carid']]\n",
    "\n",
    "    charging_order_agg.fillna(0,inplace=True) \n",
    "    return charging_order_agg\n",
    "# 处理潜在充电需求\n",
    "def process_potential_demand(car_infos, step_length, params):\n",
    "    car_infos['time'] = pd.to_datetime(car_infos['time'])\n",
    "    stay_infos = car_infos.sort_values(by=['carid', 'time'])\n",
    "    stay_infos['timegap'] = (-stay_infos['time'].diff(-1).dt.total_seconds()).fillna(1000000).astype(int)\n",
    "    stay_infos['etime'] = stay_infos['time'].shift(-1)\n",
    "    stay_order = stay_infos[stay_infos['timegap'] > step_length][['carid', 'time', 'etime', 'soc', 'lon', 'lat']]\n",
    "    stay_order.columns = ['carid', 'stime', 'etime', 'soc', 'lon', 'lat']\n",
    "    stay_order['duration'] = (stay_order['etime'] - stay_order['stime']).dt.total_seconds()\n",
    "    stay_order = stay_order[(stay_order[\"soc\"] <= 50) & (stay_order[\"duration\"] >= 60 * 5)]\n",
    "    stay_order['LONCOL'], stay_order['LATCOL'] = tbd.GPS_to_grid(stay_order['lon'], stay_order['lat'], params=params)\n",
    "    stay_order_agg = stay_order.groupby(['LONCOL', 'LATCOL']).size().reset_index()\n",
    "    stay_order_agg.columns=['LONCOL','LATCOL',\"pdemand\"]\n",
    "    return stay_order_agg\n",
    "\n",
    "# 处理 POI 数据\n",
    "def process_poi(poi_data, grid, params, poi_types=['停车场', '加油站']):\n",
    "    poi_data = poi_data[poi_data[\"pname\"] == \"上海市\"]\n",
    "    poi_data['ttype'] = poi_data['type'].apply(lambda x: x.split(';')[0])\n",
    "    poi_data[\"lon\"] = poi_data['location'].apply(lambda x: x.split(',')[0])\n",
    "    poi_data[\"lat\"] = poi_data['location'].apply(lambda x: x.split(',')[1])\n",
    "    poi_data = poi_data[poi_data[\"type\"].str.contains('|'.join(poi_types))]\n",
    "    poi_data[\"lon\"] = poi_data[\"lon\"].astype(\"float\")\n",
    "    poi_data[\"lat\"] = poi_data[\"lat\"].astype(\"float\")\n",
    "    poi_data['LONCOL'], poi_data['LATCOL'] = tbd.GPS_to_grid(poi_data['lon'], poi_data['lat'], params=params)\n",
    "    poi_agg = poi_data.groupby(['LONCOL', 'LATCOL']).size().reset_index()\n",
    "    poi_agg = pd.merge(poi_agg, grid[['LONCOL', 'LATCOL']], on=['LONCOL', 'LATCOL'], how=\"right\")\n",
    "    poi_agg.columns = ['LONCOL', 'LATCOL', \"park\"]\n",
    "    poi_agg.fillna(0, inplace=True)\n",
    "    return poi_agg\n",
    "\n",
    "\n",
    "# 处理充电站的利用率\n",
    "def calculate_utilization(charging_orders, grid, params):\n",
    "    \"\"\"\n",
    "    计算充电站的充电需求满足度（利用率）。\n",
    "    \n",
    "    参数:\n",
    "    - charging_orders: 包含充电订单的DataFrame，至少应包含 ['stime', 'station_id', 'lon', 'lat', 'max_capacity', 'duration']\n",
    "    - grid: 栅格数据，用于进行GPS坐标转换和聚合。\n",
    "    - params: 栅格化参数。\n",
    "\n",
    "    返回:\n",
    "    - station_chargetime_agg: DataFrame, 包含聚合后的利用率数据，按栅格坐标（LONCOL, LATCOL）。\n",
    "    \"\"\"\n",
    "    # 确定充电订单中的最早和最晚时间\n",
    "    start_time = charging_orders[\"stime\"].min()\n",
    "    end_time = charging_orders[\"stime\"].max()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    # 计算每个充电站的充电时长（duration）\n",
    "    station_chargetime = charging_orders.groupby([\"station_id\", \"lon\", \"lat\", \"max_capacity\"])[\"duration\"].sum().reset_index()\n",
    "\n",
    "    # 转换为timedelta格式\n",
    "    station_chargetime[\"duration\"] = pd.to_timedelta(station_chargetime[\"duration\"], unit='s')\n",
    "\n",
    "    # 计算充电站的利用率\n",
    "    station_chargetime[\"uti\"] = station_chargetime[\"duration\"] / (duration * station_chargetime[\"max_capacity\"])\n",
    "\n",
    "    # 将站点的经纬度转换为栅格坐标\n",
    "    station_chargetime['LONCOL'], station_chargetime['LATCOL'] = tbd.GPS_to_grid(station_chargetime['lon'], station_chargetime['lat'], params=params)\n",
    "\n",
    "    # 按照栅格（LONCOL, LATCOL）聚合充电站利用率\n",
    "    station_chargetime_agg = station_chargetime.groupby(['LONCOL', 'LATCOL']).mean().reset_index()\n",
    "\n",
    "    # 将聚合后的利用率数据与栅格进行合并\n",
    "    station_chargetime_agg = pd.merge(station_chargetime_agg, grid[['LONCOL', 'LATCOL']], on=['LONCOL', 'LATCOL'], how=\"right\")[['LONCOL', 'LATCOL', 'uti']]\n",
    "\n",
    "    # 处理空值情况\n",
    "    station_chargetime_agg.fillna(0, inplace=True)\n",
    "\n",
    "    return station_chargetime_agg\n",
    "\n",
    "\n",
    "# 计算建站成本\n",
    "def process_station_cost(price_data, grid, params):\n",
    "    price_data[\"geometry\"] = gpd.points_from_xy(price_data[\"lon\"], price_data[\"lat\"])\n",
    "    price_data = gpd.GeoDataFrame(price_data, geometry=price_data[\"geometry\"])\n",
    "    price_data.crs = \"EPSG:4326\"\n",
    "    price_data = price_data.to_crs(\"EPSG:32651\")\n",
    "    buffer = price_data.buffer(1000)\n",
    "    price_data = gpd.GeoDataFrame(price_data, geometry=buffer)\n",
    "    pricegrid = grid.to_crs(\"EPSG:32651\")\n",
    "    pricegrid = gpd.sjoin(pricegrid, price_data)\n",
    "    pricegrid = pricegrid.groupby([\"LONCOL\", \"LATCOL\"])[\"price\"].mean().reset_index()\n",
    "\n",
    "    pricegrid[\"price\"] = pricegrid[\"price\"] * 100 * 0.02 * 0.1 * 20 + 200000 + 400000 + 0.4 * (pricegrid[\"price\"] * 100 * 0.02 * 0.1 * 20 + 200000 + 400000)\n",
    "    pricegrid = pd.merge(pricegrid, grid, how=\"right\", on=['LONCOL', 'LATCOL'])\n",
    "    pricegrid.fillna(pricegrid[\"price\"].min(), inplace=True)\n",
    "    pricegrid = pricegrid[['LONCOL', 'LATCOL', \"price\"]]\n",
    "    return pricegrid\n",
    "\n",
    "\n",
    "# 整合栅格\n",
    "def merge_grid(station_info_path, taz_path, car_infos_path, poi_path, price_path, gridfile_path, gridgejson_path):\n",
    "    # 加载数据\n",
    "    station_info = pd.read_csv(station_info_path)\n",
    "    taz = gpd.read_file(taz_path)\n",
    "    car_infos = pd.read_csv(car_infos_path)\n",
    "    poi = pd.read_excel(poi_path)\n",
    "    price = pd.read_csv(price_path)\n",
    "    gridfile = gridfile_path\n",
    "    gridgejson = gridgejson_path\n",
    "\n",
    "    # 设置栅格化参数\n",
    "    paramssh = {'slon': 120.88125, 'slat': 30.7125, 'deltalon': 0.0125, 'deltalat': 0.008333, 'theta': 0, 'method': 'rect', 'gridsize': 1000}\n",
    "    grid, paramssh = tbd.area_to_grid(taz, params=paramssh)\n",
    "\n",
    "    # 处理订单数据\n",
    "    step_length = 5 * 60\n",
    "    station_info_table ,current_car_infos, waiting_car_infos = process_charging_orders(station_info, step_length, paramssh)\n",
    "    charging_orders = get_charging_order(station_info_table,current_car_infos, step_length)\n",
    "    #处理充电需求数据\n",
    "    charging_order_agg=get_order(charging_orders,paramssh,grid)\n",
    "    # 处理潜在充电需求\n",
    "    stay_order_agg = process_potential_demand(car_infos, step_length, paramssh)\n",
    "    # 处理POI\n",
    "    poi_agg = process_poi(poi, grid, paramssh)\n",
    "\n",
    "    # 处理充电站利用率\n",
    "    station_chargetime_agg = calculate_utilization(charging_orders, grid, paramssh)\n",
    "\n",
    "\n",
    "    # 计算建站成本\n",
    "    pricegrid = process_station_cost(price, grid, paramssh)\n",
    "\n",
    "    gridsum=pd.merge(charging_order_agg,stay_order_agg,on=['LONCOL','LATCOL'])\n",
    "    gridsum=pd.merge(gridsum,poi_agg,on=['LONCOL','LATCOL'])\n",
    "    gridsum=pd.merge(gridsum,station_chargetime_agg,on=['LONCOL','LATCOL'])\n",
    "    gridsum=pd.merge(gridsum,pricegrid,on=['LONCOL','LATCOL'])\n",
    "\n",
    "    gridsum.columns=['LONCOL','LATCOL',\"demand\",\"pdemand\",\"park\",\"uti\",\"price\"]\n",
    "\n",
    "    gridsum.to_csv(gridfile,index=False)\n",
    "\n",
    "    grid.to_file(gridgejson)\n",
    "\n",
    "    # 数据汇总（如果需要后续处理，可以在这里继续处理或保存）\n",
    "    return gridsum\n",
    "\n",
    "# 数据预处理函数\n",
    "def preprocess_data(gridsum):\n",
    "    df = gridsum.copy()\n",
    "    df = df[df[\"uti\"] <= 0.5]  # 保证利用率 <= 0.5\n",
    "    df = df[df[\"park\"] >= 1]   # 保证停车位数 >= 1\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df[\"demand\"] = df[\"demand\"].astype(float)\n",
    "    df[\"pdemand\"] = df[\"pdemand\"].astype(float)\n",
    "    return df\n",
    "\n",
    "# 目标函数：只考虑充电需求和潜在充电需求\n",
    "def objective_function(individual, df):\n",
    "    selected_indices = [i for i in range(len(individual)) if individual[i] == 1]\n",
    "    total_score = 0\n",
    "    for i in selected_indices:\n",
    "        D_it = df.at[i, 'demand']\n",
    "        P_it = df.at[i, 'pdemand']\n",
    "        total_score += (D_it + P_it)\n",
    "    return total_score\n",
    "\n",
    "# 约束条件检查函数\n",
    "def satisfies_constraints(individual, df, max_cost, max_sites):\n",
    "    selected_indices = [i for i in range(len(individual)) if individual[i] == 1]\n",
    "    if not selected_indices or len(selected_indices) != max_sites:\n",
    "        return False  # 如果没有选中的栅格或选中的栅格数不等于max_sites，则返回不满足约束\n",
    "\n",
    "    total_cost = df.iloc[selected_indices]['price'].sum()\n",
    "\n",
    "    # 条件1：用地约束\n",
    "    land_availability = all(df.iloc[selected_indices]['park'] > 0)\n",
    "\n",
    "    # 条件2：充电需求满足度约束\n",
    "    demand_satisfaction = all(df.iloc[selected_indices]['uti'] <= 0.5)\n",
    "\n",
    "    # 条件3：建站成本约束\n",
    "    cost_constraint = total_cost <= max_cost\n",
    "\n",
    "    return land_availability and demand_satisfaction and cost_constraint\n",
    "\n",
    "# 评价函数\n",
    "def evaluate(individual, df, max_cost, max_sites):\n",
    "    if satisfies_constraints(individual, df, max_cost, max_sites):\n",
    "        return objective_function(individual, df),\n",
    "    else:\n",
    "        return 0.0,  # 不满足约束条件的个体适应度设为0\n",
    "\n",
    "# 初始化个体的函数\n",
    "def init_individual(icls, df, size, num_ones, target_cost):\n",
    "    individual = [0] * size\n",
    "    df_sorted = df.copy()\n",
    "    df_sorted['demand_pdemand_sum'] = df['demand'] + df['pdemand']\n",
    "\n",
    "    df_high_cost = df_sorted[df_sorted['price'] > target_cost].sort_values(by=['demand_pdemand_sum', 'price'], ascending=[False, True])\n",
    "    df_low_cost = df_sorted[df_sorted['price'] <= target_cost].sort_values(by=['demand_pdemand_sum', 'price'], ascending=[False, False])\n",
    "\n",
    "    selected_indices = []\n",
    "\n",
    "    high_cost_count = min(len(df_high_cost), num_ones // 2)\n",
    "    selected_indices.extend(df_high_cost.index[:high_cost_count])\n",
    "\n",
    "    remaining_count = num_ones - len(selected_indices)\n",
    "    selected_indices.extend(df_low_cost.index[:remaining_count])\n",
    "\n",
    "    for idx in selected_indices:\n",
    "        individual[idx] = 1\n",
    "\n",
    "    return icls(individual)\n",
    "\n",
    "# 自定义变异函数，确保变异后仍然有固定数量的1\n",
    "def mut_shuffle_indexes(individual, indpb):\n",
    "    if np.random.random() < indpb:\n",
    "        ones_indices = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "        zeros_indices = [i for i, bit in enumerate(individual) if bit == 0]\n",
    "        if ones_indices and zeros_indices:\n",
    "            swap_out = np.random.choice(ones_indices)\n",
    "            swap_in = np.random.choice(zeros_indices)\n",
    "            individual[swap_out], individual[swap_in] = individual[swap_in], individual[swap_out]\n",
    "    return individual,\n",
    "\n",
    "# 初始化遗传算法工具\n",
    "def init_toolbox(df, cost, max_sites):\n",
    "    # 注册工具\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", init_individual, creator.Individual, df=df, size=len(df), num_ones=max_sites, target_cost=cost)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", mut_shuffle_indexes, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evaluate, df=df, max_cost=cost, max_sites=max_sites)\n",
    "    return toolbox\n",
    "\n",
    "# 遗传算法主函数\n",
    "def genetic_algorithm(toolbox, population_size, generations, cxpb, mutpb):\n",
    "    pop = toolbox.population(n=population_size)\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=generations, verbose=True)\n",
    "\n",
    "    best_individual = tools.selBest(pop, k=1)[0]\n",
    "    selected_indices = [i for i in range(len(best_individual)) if best_individual[i] == 1]\n",
    "    return selected_indices\n",
    "\n",
    "# 主调用函数\n",
    "def run_site_selection(gridsum, cost=120*10000, population_size=900, generations=200, cxpb=0.5, mutpb=0.2, max_sites=100):\n",
    "    # 数据预处理\n",
    "    \n",
    "    df = preprocess_data(gridsum)\n",
    "\n",
    "    # 初始化工具\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = init_toolbox(df, cost, max_sites)\n",
    "\n",
    "    # 执行遗传算法\n",
    "    optimal_sites = genetic_algorithm(toolbox, population_size, generations, cxpb, mutpb)\n",
    "\n",
    "    # 筛选出最优站点数据\n",
    "    optimal_grid_data = df.iloc[optimal_sites]\n",
    "    return optimal_grid_data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t900   \n",
      "1  \t552   \n",
      "2  \t561   \n",
      "3  \t548   \n",
      "4  \t547   \n",
      "5  \t544   \n",
      "6  \t530   \n",
      "7  \t530   \n",
      "8  \t554   \n",
      "9  \t545   \n",
      "10 \t543   \n",
      "11 \t534   \n",
      "12 \t567   \n",
      "13 \t539   \n",
      "14 \t542   \n",
      "15 \t542   \n",
      "16 \t535   \n",
      "17 \t550   \n",
      "18 \t569   \n",
      "19 \t524   \n",
      "20 \t534   \n",
      "21 \t565   \n",
      "22 \t535   \n",
      "23 \t539   \n",
      "24 \t575   \n",
      "25 \t524   \n",
      "26 \t522   \n",
      "27 \t515   \n",
      "28 \t547   \n",
      "29 \t526   \n",
      "30 \t542   \n",
      "31 \t534   \n",
      "32 \t569   \n",
      "33 \t530   \n",
      "34 \t556   \n",
      "35 \t516   \n",
      "36 \t547   \n",
      "37 \t541   \n",
      "38 \t561   \n",
      "39 \t525   \n",
      "40 \t546   \n",
      "41 \t538   \n",
      "42 \t523   \n",
      "43 \t557   \n",
      "44 \t500   \n",
      "45 \t550   \n",
      "46 \t526   \n",
      "47 \t543   \n",
      "48 \t528   \n",
      "49 \t525   \n",
      "50 \t514   \n",
      "51 \t559   \n",
      "52 \t523   \n",
      "53 \t533   \n",
      "54 \t531   \n",
      "55 \t533   \n",
      "56 \t553   \n",
      "57 \t506   \n",
      "58 \t544   \n",
      "59 \t532   \n",
      "60 \t518   \n",
      "61 \t540   \n",
      "62 \t546   \n",
      "63 \t537   \n",
      "64 \t518   \n",
      "65 \t556   \n",
      "66 \t544   \n",
      "67 \t582   \n",
      "68 \t512   \n",
      "69 \t576   \n",
      "70 \t525   \n",
      "71 \t570   \n",
      "72 \t583   \n",
      "73 \t537   \n",
      "74 \t546   \n",
      "75 \t535   \n",
      "76 \t550   \n",
      "77 \t548   \n",
      "78 \t520   \n",
      "79 \t552   \n",
      "80 \t543   \n",
      "81 \t519   \n",
      "82 \t554   \n",
      "83 \t554   \n",
      "84 \t550   \n",
      "85 \t560   \n",
      "86 \t579   \n",
      "87 \t532   \n",
      "88 \t546   \n",
      "89 \t540   \n",
      "90 \t531   \n",
      "91 \t494   \n",
      "92 \t557   \n",
      "93 \t515   \n",
      "94 \t533   \n",
      "95 \t547   \n",
      "96 \t546   \n",
      "97 \t527   \n",
      "98 \t576   \n",
      "99 \t551   \n",
      "100\t532   \n",
      "101\t533   \n",
      "102\t550   \n",
      "103\t507   \n",
      "104\t567   \n",
      "105\t531   \n",
      "106\t522   \n",
      "107\t566   \n",
      "108\t553   \n"
     ]
    }
   ],
   "source": [
    "from site_genetic import merge_grid\n",
    "from site_genetic import run_site_selection\n",
    "# 示例调用\n",
    "if __name__ == \"__main__\":\n",
    "    station_info_path = r'D:\\北大深\\华为充电桩网络优化\\第二阶段城市场景\\仿真结果\\output_10W_v2\\output_10W_v2\\station_infos.csv'\n",
    "    taz_path = r\"D:\\北大深\\华为充电桩网络优化\\第二阶段城市场景\\taz.geojson\"\n",
    "    car_infos_path = r'D:\\北大深\\华为充电桩网络优化\\第二阶段城市场景\\仿真结果\\output_10W_v2\\output_10W_v2\\car_infos.csv'\n",
    "    poi_path = r\"D:\\北大深\\充电桩环境影响\\poi\\gd_310000_poi.xlsx\"\n",
    "    price_path = r\"D:\\北大深\\华为充电桩网络优化\\第二阶段城市场景\\POI\\上海房价.csv\"\n",
    "    gridfile_path = r\"D:\\北大深\\华为充电桩网络优化\\选址\\gridsum.csv\"\n",
    "    gridgejson_path = r\"D:\\北大深\\华为充电桩网络优化\\选址\\grid.geojson\"\n",
    "    gridsum = merge_grid(station_info_path, taz_path, car_infos_path, poi_path, price_path, gridfile_path, gridgejson_path)\n",
    "    result = run_site_selection(gridsum,max_sites=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# 数据预处理函数\n",
    "def preprocess_data(gridsum):\n",
    "    df = gridsum.copy()\n",
    "    df = df[df[\"uti\"] <= 0.5]  # 保证利用率 <= 0.5\n",
    "    df = df[df[\"park\"] >= 1]   # 保证停车位数 >= 1\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df[\"demand\"] = df[\"demand\"].astype(float)\n",
    "    df[\"pdemand\"] = df[\"pdemand\"].astype(float)\n",
    "    return df\n",
    "\n",
    "# 目标函数：只考虑充电需求和潜在充电需求\n",
    "def objective_function(individual, df):\n",
    "    selected_indices = [i for i in range(len(individual)) if individual[i] == 1]\n",
    "    total_score = 0\n",
    "    for i in selected_indices:\n",
    "        D_it = df.at[i, 'demand']\n",
    "        P_it = df.at[i, 'pdemand']\n",
    "        total_score += (D_it + P_it)\n",
    "    return total_score\n",
    "\n",
    "# 约束条件检查函数\n",
    "def satisfies_constraints(individual, df, max_cost, max_sites):\n",
    "    selected_indices = [i for i in range(len(individual)) if individual[i] == 1]\n",
    "    if not selected_indices or len(selected_indices) != max_sites:\n",
    "        return False  # 如果没有选中的栅格或选中的栅格数不等于max_sites，则返回不满足约束\n",
    "\n",
    "    total_cost = df.iloc[selected_indices]['price'].sum()\n",
    "\n",
    "    # 条件1：用地约束\n",
    "    land_availability = all(df.iloc[selected_indices]['park'] > 0)\n",
    "\n",
    "    # 条件2：充电需求满足度约束\n",
    "    demand_satisfaction = all(df.iloc[selected_indices]['uti'] <= 0.5)\n",
    "\n",
    "    # 条件3：建站成本约束\n",
    "    cost_constraint = total_cost <= max_cost\n",
    "\n",
    "    return land_availability and demand_satisfaction and cost_constraint\n",
    "\n",
    "# 评价函数\n",
    "def evaluate(individual, df, max_cost, max_sites):\n",
    "    if satisfies_constraints(individual, df, max_cost, max_sites):\n",
    "        return objective_function(individual, df),\n",
    "    else:\n",
    "        return 0.0,  # 不满足约束条件的个体适应度设为0\n",
    "\n",
    "# 初始化个体的函数\n",
    "def init_individual(icls, df, size, num_ones, target_cost):\n",
    "    individual = [0] * size\n",
    "    df_sorted = df.copy()\n",
    "    df_sorted['demand_pdemand_sum'] = df['demand'] + df['pdemand']\n",
    "\n",
    "    df_high_cost = df_sorted[df_sorted['price'] > target_cost].sort_values(by=['demand_pdemand_sum', 'price'], ascending=[False, True])\n",
    "    df_low_cost = df_sorted[df_sorted['price'] <= target_cost].sort_values(by=['demand_pdemand_sum', 'price'], ascending=[False, False])\n",
    "\n",
    "    selected_indices = []\n",
    "\n",
    "    high_cost_count = min(len(df_high_cost), num_ones // 2)\n",
    "    selected_indices.extend(df_high_cost.index[:high_cost_count])\n",
    "\n",
    "    remaining_count = num_ones - len(selected_indices)\n",
    "    selected_indices.extend(df_low_cost.index[:remaining_count])\n",
    "\n",
    "    for idx in selected_indices:\n",
    "        individual[idx] = 1\n",
    "\n",
    "    return icls(individual)\n",
    "\n",
    "# 自定义变异函数，确保变异后仍然有固定数量的1\n",
    "def mut_shuffle_indexes(individual, indpb):\n",
    "    if np.random.random() < indpb:\n",
    "        ones_indices = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "        zeros_indices = [i for i, bit in enumerate(individual) if bit == 0]\n",
    "        if ones_indices and zeros_indices:\n",
    "            swap_out = np.random.choice(ones_indices)\n",
    "            swap_in = np.random.choice(zeros_indices)\n",
    "            individual[swap_out], individual[swap_in] = individual[swap_in], individual[swap_out]\n",
    "    return individual,\n",
    "\n",
    "# 初始化遗传算法工具\n",
    "def init_toolbox(df, cost, max_sites):\n",
    "    # 注册工具\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", init_individual, creator.Individual, df=df, size=len(df), num_ones=max_sites, target_cost=cost)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", mut_shuffle_indexes, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evaluate, df=df, max_cost=cost, max_sites=max_sites)\n",
    "    return toolbox\n",
    "\n",
    "# 遗传算法主函数\n",
    "def genetic_algorithm(toolbox, population_size, generations, cxpb, mutpb):\n",
    "    pop = toolbox.population(n=population_size)\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=generations, verbose=True)\n",
    "\n",
    "    best_individual = tools.selBest(pop, k=1)[0]\n",
    "    selected_indices = [i for i in range(len(best_individual)) if best_individual[i] == 1]\n",
    "    return selected_indices\n",
    "\n",
    "# 主调用函数\n",
    "def run_site_selection(gridsum, cost=120*10000, population_size=900, generations=200, cxpb=0.5, mutpb=0.2, max_sites=100):\n",
    "    # 数据预处理\n",
    "    df = preprocess_data(gridsum)\n",
    "\n",
    "    # 初始化工具\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = init_toolbox(df, cost, max_sites)\n",
    "\n",
    "    # 执行遗传算法\n",
    "    optimal_sites = genetic_algorithm(toolbox, population_size, generations, cxpb, mutpb)\n",
    "\n",
    "    # 筛选出最优站点数据\n",
    "    optimal_grid_data = df.iloc[optimal_sites]\n",
    "    return optimal_grid_data\n",
    "\n",
    "# 示例调用\n",
    "if __name__ == \"__main__\":\n",
    "    gridsum = pd.read_csv(r\"D:\\北大深\\华为充电桩网络优化\\选址\\gridsum.csv\")  # 假设有一个gridsum文件\n",
    "    result = run_site_selection(gridsum)\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
